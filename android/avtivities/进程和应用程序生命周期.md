

大多数情况下，每个应用程序都运行在自己的Linux进程中，当需要运行某些代码时，将为应用程序创建进程，并且该进程将一直运行，直到不再需要它为止或者系统需要回收其内存以供其他应用程序使用。
>In most cases, every Android application runs in its own Linux process. This process is created for the application when some of its code needs to be run, and will remain running until it is no longer needed and the system needs to reclaim its memory for use by other applications.

Android的一个不寻常的基本特征是应用程序进程的生命周期不是由应用程序本身直接控制的。 相反，应用的进程存活由系统确定的，系统通过判断正在运行的应用程序对用户的重要性以及系统中可用的总内存的大小来确定哪些进程可以保留在内存中。
>An unusual and fundamental feature of Android is that an application process's lifetime is not directly controlled by the application itself. Instead, it is determined by the system through a combination of the parts of the application that the system knows are running, how important these things are to the user, and how much overall memory is available in the system.

对于应用程序开发人员，了解不同的应用程序组件（特别是Activity，Service和BroadcastReceiver）如何影响应用程序进程的生命周期是非常重要的。 **不正确地使用这些组件会导致系统终止正在执行重要工作时的应用程序的进程**。
>It is important that application developers understand how different application components (in particular Activity, Service, and BroadcastReceiver) impact the lifetime of the application's process. **Not using these components correctly can result in the system killing the application's process while it is doing important work.**

进程生命周期错误的一个常见示例是BroadcastReceiver，如果在BroadcastReceiver.onReceive（）方法接收到Intent时启动一个线程，然后从该函数返回。 一旦返回，系统会认为BroadcastReceiver不再处于活动状态，因此不再需要其托管进程（除非其他应用程序组件处于活动状态）。 因此，系统可能随时终止进程以回收内存，并且这样做会终止在进程中运行的刚才启动的线程。 此问题的解决方案通常是从BroadcastReceiver安排JobService，以便系统知道在该进程中仍有活动的工作。
>A common example of a process life-cycle bug is a BroadcastReceiver that starts a thread when it receives an Intent in its BroadcastReceiver.onReceive() method, and then returns from the function. Once it returns, the system considers the BroadcastReceiver to be no longer active, and thus, its hosting process no longer needed (unless other application components are active in it). So, the system may kill the process at any time to reclaim memory, and in doing so, it terminates the spawned thread running in the process. The solution to this problem is typically to schedule a JobService from the BroadcastReceiver, so the system knows that there is still active work being done in the process.

为了确定在内存不足时应该杀死哪些进程，Android会根据其中运行的组件以及这些组件的状态将每个进程置于“重要性层次结构”中。 这些进程的类型是（按重要性排序）：
    1. **前台进程** 前台进程是用户当前正在执行的操作所必需的进程。 各种应用程序组件都可以使其包含进程以不同方式被视为前台进程。 如果满足以下任何条件，则认为进程处于前台：
       * 用户正在交互的屏幕顶部运行的 *Activity* 所在的进程（正在调用activity的 onResume（）方法）。
       * 进程有一个当前正在运行的BroadcastReceiver（它的BroadcastReceiver.onReceive（）方法正在执行）。
       * 进程有一个服务，该服务当前有一个回调方法中正在执行代码（Service.onCreate（），Service.onStart（）或Service.onDestroy（））。

>To determine which processes should be killed when low on memory, Android places each process into an "importance hierarchy" based on the components running in them and the state of those components. These process types are (in order of importance):
   1. A **foreground process** is one that is required for what the user is currently doing. Various application components can cause its containing process to be considered foreground in different ways. A process is considered to be in the foreground if any of the following conditions hold:
      * It is running an Activity at the top of the screen that the user is interacting with (its onResume() method has been called).
      * It has a BroadcastReceiver that is currently running (its BroadcastReceiver.onReceive() method is executing).
      * It has a Service that is currently executing code in one of its callbacks (Service.onCreate(), Service.onStart(), or Service.onDestroy()).
   There will only ever be a few such processes in the system, and these will only be killed as a last resort if memory is so low that not even these processes can continue to run. Generally, at this point, the device has reached a memory paging state, so this action is required in order to keep the user interface responsive.
   2. A **visible process** is doing work that the user is currently aware of, so killing it would have a noticeable negative impact on the user experience. A process is considered visible in the following conditions:
      * It is running an Activity that is visible to the user on-screen but not in the foreground (its onPause() method has been called). This may occur, for example, if the foreground Activity is displayed as a dialog that allows the previous Activity to be seen behind it.
      * It has a Service that is running as a foreground service, through Service.startForeground() (which is asking the system to treat the service as something the user is aware of, or essentially visible to them).
      * It has a Service that is running as a foreground service, through Service.startForeground() (which is asking the system to treat the service as something the user is aware of, or essentially visible to them).
   The number of these processes running in the system is less bounded than foreground processes, but still relatively controlled. These processes are considered extremely important and will not be killed unless doing so is required to keep all foreground processes running.
   3. The number of these processes running in the system is less bounded than foreground processes, but still relatively controlled. These processes are considered extremely important and will not be killed unless doing so is required to keep all foreground processes running.
   Services that have been running for a long time (such as 30 minutes or more) may be demoted in importance to allow their process to drop to the cached LRU list described next. This helps avoid situations where very long running services with memory leaks or other problems consume so much RAM that they prevent the system from making effective use of cached processes.
   4. A cached process is one that is not currently needed, so the system is free to kill it as desired when memory is needed elsewhere. In a normally behaving system, these are the only processes involved in memory management: a well running system will have multiple cached processes always available (for more efficient switching between applications) and regularly kill the oldest ones as needed. Only in very critical (and undesireable) situations will the system get to a point where all cached processes are killed and it must start killing service processes.
   
   A cached process is one that is not currently needed, so the system is free to kill it as desired when memory is needed elsewhere. In a normally behaving system, these are the only processes involved in memory management: a well running system will have multiple cached processes always available (for more efficient switching between applications) and regularly kill the oldest ones as needed. Only in very critical (and undesireable) situations will the system get to a point where all cached processes are killed and it must start killing service processes.

   These processes are kept in a pseudo-LRU list, where the last process on the list is the first killed to reclaim memory. The exact policy of ordering on this list is an implementation detail of the platform, but generally it will try to keep more useful processes (one hosting the user's home application, the last activity they saw, etc) before other types of processes. Other policies for killing processes may also be applied: hard limits on the number of processes allowed, limits on the amount of time a process can stay continually cached, etc.

When deciding how to classify a process, the system will base its decision on the most important level found among all the components currently active in the process. See the Activity, Service, and BroadcastReceiver documentation for more detail on how each of these components contribute to the overall life-cycle of a process. The documentation for each of these classes describes in more detail how they impact the overall life-cycle of their application.

A process's priority may also be increased based on other dependencies a process has to it. For example, if process A has bound to a Service with the Context.BIND_AUTO_CREATE flag or is using a ContentProvider in process B, then process B's classification will always be at least as important as process A's.
